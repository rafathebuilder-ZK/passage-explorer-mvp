<p>Coordination failures in contemporary organizations increasingly arrive with receipts. The incident report shows that the checklist was followed, the workflow was executed, the approvals were captured, the fields were filled, the branch protection rules were satisfied, the pull request was merged, the audit trail is intact. And still, something is off. The work is late in the way that makes everyone slightly mean. The product ships in the way that creates a new category of maintenance. The team “did the process” and ended up with less confidence, less shared understanding, and fewer people willing to touch the hot parts of the system next time. This is the small scandal of protocol-saturated life: coordinated behavior can be produced while competent action quietly evaporates. The locus of coordination appears to have migrated from people to systems, and the migration is sufficiently gradual that it passes as modernization rather than as a change in what coordination is.</p><p>A useful way to approach this shift is to resist beginning with protocols as stable objects. Protocols are tempting because they are legible; they sit still long enough to be named, diagrammed, versioned, and audited. Practice refuses that kind of stillness. Practice is where time shows up. It is where competence is made, and where it wears down. It is where someone notices that the category is wrong, the exception is becoming the norm, the “edge case” is now Tuesday. In Wenger’s account, a community of practice is held together by a jointly negotiated enterprise, mutual engagement, and a shared repertoire of routines, sensibilities, vocabulary, and artifacts, produced through participation over time (Wenger 1998). In that picture, <strong>competence is a living achievement of a group that learns itself into coherence.</strong> The community can be influenced by mandates, though the mandate does not produce the practice; the community produces the practice as its response to what matters and what is demanded (Wenger 1998). This is already a warning about protocols. A protocol can be mandated, yet the capacity to enact it competently remains a social accomplishment that does not automatically follow from the mandate.</p><p>Summer of Protocols offers a definition that helps clarify what protocols are doing when they work and what they are doing when they fail. A protocol can be understood as an engineered argument, and the “argument” is built to manage tensions rather than to eliminate them. A tension, in the same source, is a tradeoff plus a conflict, which matters because tradeoffs can be privately endured while conflicts recruit factions (Protocol Reader 2025). In this framing, <strong>protocols are devices for stabilizing recurring tensions so that coordinated behavior becomes possible at scale.</strong> They are more than rules; they are packaged decisions about what will count as an acceptable resolution of a conflict-laden tradeoff. The package can travel. The stabilization can persist. The argument can be enforced.</p><p>The pairing of Wenger’s practice and Summer of Protocols’ engineered argument immediately suggests an asymmetry. <strong>Practice is the primary site where situated judgment is developed and sustained. Protocols are secondary in the sense that they are assembled from residues of that judgment.</strong> They are abstractions that condense what a community learned was worth doing repeatedly and reliably. Weick’s insistence that theorizing is activity, while theory is a product, sharpens the point: the product has advantages of portability and communicability, and it risks severing itself from the process that generated its plausibility (Weick 1995). Protocols have the same double character. They are artifacts of ongoing work, and they are also attempts to freeze a portion of that work into an object that can act elsewhere. Freezing buys reach. It also buys context loss.</p><p><strong>The temptation at this point is to treat context loss as a defect.</strong> That temptation is understandable and misleading. Abstraction is how a practice extends itself beyond the intimate radius of a small group. <strong>A protocol can expand the capacity of a community by allowing coordination among people who do not share history, proximity, or continuous mutual engagement.</strong> Wenger notes that communities of practice can move information across organizational boundaries, retain knowledge in living ways that manuals and databases fail to capture, and initiate newcomers into the practice through participation in a shared repertoire (Wenger 1998). Protocols, as one element in that repertoire, are part of how a practice becomes transmissible. They increase reach across time and distance, and they provide continuity in environments where membership turns over. The Protocol Reader’s discussion of protocols engineered into the built environment makes the same point with a different vocabulary: embedding protocols into an environment can free up mental bandwidth, while creating a need for maintenance as a meta-protocol to sustain rigid constraints at scale (Protocol Reader 2025). Capacity and maintenance are coupled. Scale and repair are coupled. A protocol is not a pure gift, and it is not a pure burden.</p><p>The real issue begins when the coupling is broken. Software has become the dominant medium for breaking it, because software does not merely represent protocols; it executes them. <strong>When a protocol is embedded in software, it begins to define the space of possible actions, the states that are reachable, the data that must be supplied, and the outcomes that the system will recognize as complete.</strong> At that point, the protocol becomes less like guidance and more like an environment. People can still exercise judgment, though the judgment increasingly takes the form of navigating what the system will accept. The authority of the protocol shifts from practitioner validation to system enforcement. The protocol can now coordinate behavior even when the community that once sustained its meaning is absent, weakened, or subordinated.</p><p>Management makes this dynamic visible because it is, at base, a practice of coordinating attention and responsibility under uncertainty. Drucker’s effective executive is a practitioner of choice under constraint: concentration, sequencing, the discipline of “first things first,” and the conversion of intentions into commitments that can be acted upon (Drucker 2006). Strategy, in Porter’s canonical account, is organized around tradeoffs that are chosen and then maintained; strategic positioning requires choosing what to do and sustaining the incompatibilities that prevent the activity system from dissolving into imitative mush (Porter 1996). Lean Startup adds a process language for uncertainty: build-measure-learn cycles that accelerate feedback and force decisions about whether to pivot or persevere (Ries; Lean Startup principles). Across these traditions, management is not reducible to formal structure or policy documents. It is the ongoing work of making tradeoffs, allocating responsibility, maintaining attention, and repairing breakdowns in shared understanding. It is also the work of noticing when the environment has changed enough that yesterday’s tradeoffs produce today’s conflicts.</p><p>This is where Git becomes an instructive anchor example, because Git is widely understood as a software tool, and it also functions as a protocol: a codified stratum of behavior that enables complex coordinated behaviors among adjacent loci, to borrow the Protocol Reader’s early definition (Protocol Reader 2025). Git records changes over time, preserves history, and allows coordination across distributed contributors (git-scm documentation). It was developed in 2005 in the context of Linux kernel development as a response to the needs of coordinating a large, distributed project, with design emphasis on speed, non-linear development, and distributed work (Git documentation; GitHub’s 20th anniversary Q&amp;A). <strong>Git is therefore a protocol that emerged in a managerial context, even if that context is an engineering community rather than a corporate hierarchy.</strong> It encodes judgments about attribution, sequencing, conflict resolution, and responsibility. Those judgments are recognizably managerial. They answer questions that management must answer, even when the “managers” are maintainers and the “organization” is an open-source project.</p><p>Consider what a commit is. Technically, it is a snapshot of changes addressed by a checksum; practically, it is an assertion of authorship and a claim about the coherence of a set of edits. Git’s integrity model, in which everything is checksummed and referred to by that checksum, builds tamper-evidence into the substrate (git-scm). This is a technical detail that carries a governance implication: the history becomes a stable reference point for accountability and diagnosis. When something breaks, the community can locate where the break entered, who authored the change, what else was bundled with it, and how it relates to other work. That is a managerial capacity: retrospective traceability in service of repair and learning.</p><p>Consider branching and merging. Branches allow parallel work without immediate consensus, which is a way of stabilizing the tension between autonomy and coordination. You can proceed without blocking others, and the merging moment becomes the point where conflicts are surfaced and resolved. Merge conflicts are operationalized disagreement. Git forces the disagreement to become explicit at the boundary between branches. This is again managerial, in the sense that it externalizes conflict into a visible artifact that must be resolved before the system recognizes completion. The protocol provides a mechanism for turning a potentially social conflict into a procedural conflict with a constrained resolution space. That is an engineered argument.</p><p>Consider the pull request workflow layered on top of Git in contemporary platforms. A pull request is a proposal to merge a set of changes from one branch into another, with a built-in space for review and discussion, after which approval and merging integrates changes into the main codebase (GitHub documentation). Branch protection rules, mandatory reviews, status checks, and automated test gates are further codifications. The protocol defines who must look, what must pass, what evidence is required, and what counts as “ready.” The managerial judgment that used to live in conversations, norms, and tacit expectations becomes embedded in the workflow. The workflow scales. It also sets boundaries on discretion.</p><p>At this point, one might say Git is simply a tool for engineers. That statement misses the way tools become governance when they stabilize tensions and allocate responsibility. Git was built for a high-tempo environment where distributed contributors needed reliable coordination without central bottlenecks. Its distributed nature allows local work, offline work, and rapid branching and merging, while maintaining a coherent history across contributors (Git documentation). These are precisely the conditions under which managerial practices often struggle: dispersed teams, asynchronous collaboration, and high cost of miscoordination. Git provides a protocolized solution. It increases capacity, reach, and durability of coordination. It extends practice.</p><p>The extension, however, carries a structural inversion once Git becomes embedded in modern toolchains. In a small community, Git is a shared repertoire within a practice. People learn it socially. They teach each other what a “good commit” looks like, how to write messages that future maintainers can interpret, when to squash, when to rebase, how to handle merges without turning history into a landfill. These are judgments that belong to a community of practice. Wenger emphasizes that communities retain knowledge in living ways and that participation is what sustains learning (Wenger 1998). In that setting, Git is pliable because the practice can interpret it.</p><p>In a large organization, Git becomes integrated into identity management, ticketing systems, CI pipelines, deployment gates, compliance regimes, and performance evaluation. The pull request is no longer a local proposal among peers; it is a unit of managerial visibility. It becomes legible to dashboards. It becomes countable. It becomes an evidence object for reviews, audits, and security attestations. The protocol is now operationally dominant because the system enforces it. Your changes do not exist, organizationally, until they are in the system in an approved state. Work that is not legible to the protocol becomes, in practical terms, unreal.</p><p>This is where “subsumption into software architecture” becomes a useful label. (NPC Memo, December 2025). Management is increasingly performed through the configuration and operation of software systems that encode managerial judgments. Git, plus its surrounding tooling, is an instance of this. The practice of management that once relied on situated judgment about who should review what, how much evidence is enough, when speed matters more than polish, and how to handle exceptions becomes a set of enforced workflow states. The manager’s judgment migrates from action to configuration and exception handling. The organization’s theory of responsibility becomes a set of permissions, required approvals, and automated checks. <strong>The protocol becomes an environment that conditions what counts as competence: competence becomes the ability to move work through the system in approved ways, to anticipate the gates, to produce the right artifacts, to avoid triggering blocks.</strong></p><p>There is a genuine gain here. Organizations need forms of coordination that scale across turnover, time zones, and complexity. Protocols embedded in software provide continuity. They reduce cognitive load by externalizing constraints and reminders. They create shared reference points. They can improve safety and reliability by enforcing checks that tired humans skip. The Protocol Reader’s discussion of protocols built into environments, freeing mental bandwidth while requiring maintenance, captures the form of this bargain (Protocol Reader 2025). Git’s checksum-based integrity and distributed history provide robustness that would be difficult to reproduce through purely conversational norms (git-scm). The benefits are not imaginary.</p><p>The costs appear when the protocol’s operational dominance begins to outstrip its ontological dependence on practice. <strong>Protocols cannot interpret themselves. A merge conflict does not tell you which side is “right.”</strong> A test suite passing does not tell you whether the product is coherent. A required reviewer approving does not guarantee that the approval represented careful attention. These are interpretive and ethical dimensions of competent action that remain located in practice. The system can enforce that a review happened; it cannot enforce that the review was a good faith act of care. The system can enforce that a box was checked; it cannot enforce that the box was the right box. When the community of practice is strong, these limitations are buffered by shared repertoires of judgment and by a culture of repair. When the community is weak, the protocol becomes a shell that coordinates behavior while competence erodes.</p><p>Wenger points out that communities of practice can become liabilities when expertise becomes insular, and that boundaries matter because radically new insights often arise there; the organization needs to recognize, support, and leverage the processes by which learning communities evolve, rather than dismiss or impede them (Wenger 1998). This is relevant because software protocols can impede those processes by redirecting attention away from participation and toward compliance. They can also create the illusion that knowledge is being retained because artifacts are being stored. The PR thread is treated as memory. The ticket is treated as understanding. The repository is treated as the practice. Wenger explicitly warns against knowledge management approaches that treat knowledge as a thing captured in formal systems, when what matters is dynamic knowing sustained by engaged participation (Wenger 1998). Protocolized software systems are seductive because they look like repositories of knowing. They can become repositories of residues.</p><p>Weick’s concern with frozen products extends this warning. <strong>When a process is turned into a product, the product invites reuse in contexts that differ from the context of its production, and the reuse can become detached from the constraints that made it sensible (Weick 1995).</strong> The act of theorizing, or here the act of practicing, is where adjustments and repairs occur. A protocol is a partial freeze of that act. <strong>A freeze can travel farther than the act.</strong> Travel is the point. Travel is the danger.</p><p><strong>Protocol decay emerges when the travel is successful and the maintenance is underprovided.</strong> Decay is not a single failure event; it is the slow accumulation of misalignments between enforced form and competent action. The organization continues to “do Git.” The pull requests continue to flow. The checks continue to pass. At the same time, the craft norms that once made the protocol meaningful thin out. Commit messages become useless. Branches proliferate without clear intent. Reviews become rubber stamps because incentives reward throughput. Exceptions become common and are handled through workarounds that are invisible to the protocol. The protocol continues to coordinate behavior, and the practice that could repair the drift is either not present or lacks authority relative to the system’s enforcement.</p><p>This is a structural outcome because the system can scale enforcement without scaling care. The Protocol Reader’s observation that embedding protocols into environments creates a need for maintenance as a meta-protocol is a way of stating the same pattern: rigidity buys bandwidth and creates a new class of work required to keep the rigidity aligned with reality (Protocol Reader 2025). In Git-centric organizations, that maintenance work includes stewardship of workflow norms, cultivation of review quality, refactoring of branching strategies, pruning of CI flakiness, and the continuous renegotiation of what gates are appropriate for which kinds of work. If this maintenance is treated as overhead, the protocol persists and the practice decays. The organization ends up with a hardened coordination shell and a softening competence core.</p><p>One can watch the inversion by noticing what gets punished. <strong>In a protocol-dominant environment, the primary punishable offense is violating the workflow.</strong> People learn to avoid violations. They learn the dance steps. They learn how to structure work so the system will accept it. They also learn to avoid doing work that the system cannot represent easily, even when that work would increase true competence: exploratory refactors, cross-cutting design thinking, deep documentation, mentoring, boundary-spanning conversations that create shared repertoire. Wenger notes that organizations can inadvertently penalize the work involved in building communities, and that reward systems can hinder participation even when the organization claims to value knowledge (Wenger 1998). Protocol-dominant toolchains easily become reward systems because they provide metrics. The metric becomes a proxy for competence. The proxy becomes an incentive. The incentive reshapes practice.</p><p>At the same time, protocols can strengthen practice by extending its reach. Git allows a dispersed community to coordinate without requiring constant synchronous conversation. It creates a durable record that newcomers can study, which supports initiation into the practice across time. It enables non-linear development with thousands of parallel branches, which increases the community’s capacity to explore alternatives (Git documentation). These benefits are real, and they are part of why protocolization continues. The question is not whether protocols are good. The question is whether the social processes that sustain competent action are being maintained at a rate commensurate with the scaling of enforcement.</p><p>Management theory already contains the seeds of this caution. Drucker’s emphasis on concentration and on deciding what needs to be done presumes that effectiveness is a disciplined practice, achieved through judgment and sustained attention rather than through the existence of procedures alone (Drucker 2006). Porter’s emphasis on tradeoffs presumes that strategy is maintained through active choice and through resisting the drift toward compatibility that makes everything average (Porter 1996). Lean Startup’s emphasis on feedback loops presumes that learning is the product, and that the loop’s purpose is to discipline judgment through evidence rather than to ritualize iteration (Ries; Lean Startup principles). These traditions treat managerial artifacts as supports for practice, not as substitutes for it. <strong>Yet software-mediated protocols often invert that relationship by making the artifact the condition for action.</strong></p><p>Git, in its modern ecosystem, illustrates this inversion with unusual clarity because the protocol is both technical and managerial. It coordinates work. It allocates responsibility. It creates auditability. It stabilizes tensions between autonomy and control, speed and safety, experimentation and integration. As a protocol, it is an engineered argument that a certain kind of conflict-laden tradeoff can be handled through commits, branches, merges, and review gates (Protocol Reader 2025; GitHub documentation). <strong>As the protocol becomes executable through toolchains, its argument becomes operationally authoritative.</strong> The organization begins to behave as though the protocol defines the work, rather than as though the work defines the protocol.</p><p>The result is an ordinary misproportion. <strong>Protocols are asked to do more than they can do, and practices are given less of what they need to do what only they can do.</strong> Protocols can coordinate behavior at scale. Practices can interpret, adapt, and repair. The two are complements, and the complementarity is fragile because it depends on continuous investment in communities of practice. Wenger’s picture of communities as self-organizing systems whose practices are produced through participation, and whose value can be overlooked when short-term project focus dominates, is directly relevant (Wenger 1998). The Protocol Reader’s insistence that engineered protocols embedded into environments create maintenance obligations that require specialists is directly relevant (Protocol Reader 2025). Weick’s insistence that the process of theorizing is where meaning is generated, and that frozen products invite overconfidence and context loss, is directly relevant (Weick 1995). Together they suggest a thesis that is less a proclamation than a diagnosis: protocols remain ontologically secondary to practice because they are assembled from fragments of situated judgment, and they become operationally dominant when software makes them executable, shifting authority toward enforcement. Protocol decay follows when operational dominance expands faster than the community-based care and repair that keeps the protocol aligned with competent action.</p><p><strong>Restoring proportion begins with admitting the tradeoff. Protocols extend practice. They increase capacity, reach, durability, and coordination at distance. They also extract context, and the extracted context has to be paid back through maintenance, interpretation, and repair.</strong> </p><p>When the payment is skipped, the system still runs. The organization still looks coordinated. The costs show up downstream, in the thinning of judgment, in the narrowing of what counts as competence, and in the quiet disappearance of the community processes that once made the protocol workable. The protocol does not fail all at once. It succeeds in a way that changes the practice, and then it slowly succeeds past the point where it can be cared for. The paradox is familiar in systems that scale: stability and continuity are purchased by freezing; adaptability and competence are sustained by ongoing work that refuses to freeze. The problem is not that one side is right. The problem is that one side can be automated.</p>